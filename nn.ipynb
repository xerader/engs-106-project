{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 222, 'name': 'Bank Marketing', 'repository_url': 'https://archive.ics.uci.edu/dataset/222/bank+marketing', 'data_url': 'https://archive.ics.uci.edu/static/public/222/data.csv', 'abstract': 'The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).', 'area': 'Business', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 45211, 'num_features': 16, 'feature_types': ['Categorical', 'Integer'], 'demographics': ['Age', 'Occupation', 'Marital Status', 'Education Level'], 'target_col': ['y'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 2014, 'last_updated': 'Fri Aug 18 2023', 'dataset_doi': '10.24432/C5K306', 'creators': ['S. Moro', 'P. Rita', 'P. Cortez'], 'intro_paper': {'ID': 277, 'type': 'NATIVE', 'title': 'A data-driven approach to predict the success of bank telemarketing', 'authors': 'SÃ©rgio Moro, P. Cortez, P. Rita', 'venue': 'Decision Support Systems', 'year': 2014, 'journal': None, 'DOI': '10.1016/j.dss.2014.03.001', 'URL': 'https://www.semanticscholar.org/paper/cab86052882d126d43f72108c6cb41b295cc8a9e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': \"The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. \\n\\nThere are four datasets: \\n1) bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014]\\n2) bank-additional.csv with 10% of the examples (4119), randomly selected from 1), and 20 inputs.\\n3) bank-full.csv with all examples and 17 inputs, ordered by date (older version of this dataset with less inputs). \\n4) bank.csv with 10% of the examples and 17 inputs, randomly selected from 3 (older version of this dataset with less inputs). \\nThe smallest datasets are provided to test more computationally demanding machine learning algorithms (e.g., SVM). \\n\\nThe classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Input variables:\\n   # bank client data:\\n   1 - age (numeric)\\n   2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\\n                                       \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \\n   3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\\n   4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\\n   5 - default: has credit in default? (binary: \"yes\",\"no\")\\n   6 - balance: average yearly balance, in euros (numeric) \\n   7 - housing: has housing loan? (binary: \"yes\",\"no\")\\n   8 - loan: has personal loan? (binary: \"yes\",\"no\")\\n   # related with the last contact of the current campaign:\\n   9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \\n  10 - day: last contact day of the month (numeric)\\n  11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\\n  12 - duration: last contact duration, in seconds (numeric)\\n   # other attributes:\\n  13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\\n  14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\\n  15 - previous: number of contacts performed before this campaign and for this client (numeric)\\n  16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\\n\\n  Output variable (desired target):\\n  17 - y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\\n', 'citation': None}}\n",
      "           name     role         type      demographic  \\\n",
      "0           age  Feature      Integer              Age   \n",
      "1           job  Feature  Categorical       Occupation   \n",
      "2       marital  Feature  Categorical   Marital Status   \n",
      "3     education  Feature  Categorical  Education Level   \n",
      "4       default  Feature       Binary             None   \n",
      "5       balance  Feature      Integer             None   \n",
      "6       housing  Feature       Binary             None   \n",
      "7          loan  Feature       Binary             None   \n",
      "8       contact  Feature  Categorical             None   \n",
      "9   day_of_week  Feature         Date             None   \n",
      "10        month  Feature         Date             None   \n",
      "11     duration  Feature      Integer             None   \n",
      "12     campaign  Feature      Integer             None   \n",
      "13        pdays  Feature      Integer             None   \n",
      "14     previous  Feature      Integer             None   \n",
      "15     poutcome  Feature  Categorical             None   \n",
      "16            y   Target       Binary             None   \n",
      "\n",
      "                                          description  units missing_values  \n",
      "0                                                None   None             no  \n",
      "1   type of job (categorical: 'admin.','blue-colla...   None             no  \n",
      "2   marital status (categorical: 'divorced','marri...   None             no  \n",
      "3   (categorical: 'basic.4y','basic.6y','basic.9y'...   None             no  \n",
      "4                              has credit in default?   None             no  \n",
      "5                              average yearly balance  euros             no  \n",
      "6                                   has housing loan?   None             no  \n",
      "7                                  has personal loan?   None             no  \n",
      "8   contact communication type (categorical: 'cell...   None            yes  \n",
      "9                        last contact day of the week   None             no  \n",
      "10  last contact month of year (categorical: 'jan'...   None             no  \n",
      "11   last contact duration, in seconds (numeric). ...   None             no  \n",
      "12  number of contacts performed during this campa...   None             no  \n",
      "13  number of days that passed by after the client...   None            yes  \n",
      "14  number of contacts performed before this campa...   None             no  \n",
      "15  outcome of the previous marketing campaign (ca...   None            yes  \n",
      "16          has the client subscribed a term deposit?   None             no  \n"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "bank_marketing = fetch_ucirepo(id=222) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = bank_marketing.data.features \n",
    "y = bank_marketing.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(bank_marketing.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(bank_marketing.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1: 28934 samples\n"
     ]
    }
   ],
   "source": [
    "# --- Data Preprocessing ---\n",
    "\n",
    "# Assume X and y are your original DataFrames/Series.\n",
    "# Factorize each categorical column in X to ensure numeric values.\n",
    "X_factorized = X.copy()\n",
    "for col in X.columns:\n",
    "    X_factorized[col], _ = pd.factorize(X[col])\n",
    "\n",
    "# Factorize and one-hot encode the target variable.\n",
    "y_numeric, uniques = pd.factorize(y.values.ravel())\n",
    "y_tensor = torch.tensor(y_numeric, dtype=torch.long)\n",
    "y_onehot = F.one_hot(y_tensor, num_classes=2).numpy()\n",
    "\n",
    "# Create train/test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_factorized, y_onehot, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "x_train_resample, y_train_resample = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# convert resampled y_train back to one-hot encoding \n",
    "y_train_resample = F.one_hot(torch.tensor(y_train_resample), num_classes=2).numpy()\n",
    "\n",
    "# --- Neural Network Class Definition ---\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, lr=0.001):\n",
    "        self.lr = lr\n",
    "        # Initialize weights with small random values and biases with zeros.\n",
    "        self.W1 = np.random.randn(input_size, hidden_size1) * lr\n",
    "        self.b1 = np.zeros((1, hidden_size1))\n",
    "        \n",
    "        self.W2 = np.random.randn(hidden_size1, hidden_size2) * lr\n",
    "        self.b2 = np.zeros((1, hidden_size2))\n",
    "        \n",
    "        self.W3 = np.random.randn(hidden_size2, output_size) * lr\n",
    "        self.b3 = np.zeros((1, output_size))\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def ReLu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Implement a 3 layer neural network forward propagation\"\"\"\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        self.X = X\n",
    "        self.z1 = np.dot(self.X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        \n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        \n",
    "        self.z3 = np.dot(self.a2, self.W3) + self.b3\n",
    "        output = self.softmax(self.z3)\n",
    "        return output \n",
    "    \n",
    "    def compute_loss(self, y, output, weight=None):\n",
    "        \"\"\"\n",
    "        Compute Cross Entropy Loss, where y is one-hot encoded and output is the softmax output.\n",
    "        \"\"\"\n",
    "        m = y.shape[0]\n",
    "        if weight is not None:\n",
    "            weight = weight.reshape(1, -1)\n",
    "            loss = -1/m * np.sum(weight * (y * np.log(output)))\n",
    "        else:\n",
    "            loss = -1/m * np.sum(y * np.log(output))\n",
    "        return loss\n",
    "            \n",
    "    def backward(self, X, y, output):\n",
    "        \"\"\"Backward propagation\"\"\"\n",
    "        m = y.shape[0]\n",
    "        # Output layer gradients\n",
    "        dZ3 = output - y\n",
    "        dW3 = np.dot(self.a2.T, dZ3) / m\n",
    "        db3 = np.sum(dZ3, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Propagate to second hidden layer\n",
    "        dA2 = np.dot(dZ3, self.W3.T)\n",
    "        dZ2 = dA2 * (self.a2 * (1 - self.a2))\n",
    "        dW2 = np.dot(self.a1.T, dZ2) / m\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Propagate to first hidden layer\n",
    "        dA1 = np.dot(dZ2, self.W2.T)\n",
    "        dZ1 = dA1 * (self.a1 * (1 - self.a1))\n",
    "        dW1 = np.dot(X.T, dZ1) / m\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Update weights and biases using gradient descent\n",
    "        self.W3 -= self.lr * dW3\n",
    "        self.b3 -= self.lr * db3\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1\n",
    "\n",
    "    def train(self, X, y, epochs, batch_size=64):\n",
    "        \"\"\"Batch Gradient Descent training\"\"\"\n",
    "        m = X.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            indices = np.random.choice(m, batch_size, replace=False)\n",
    "            # Use .iloc for DataFrame and direct indexing for numpy arrays.\n",
    "            X_batch = X.iloc[indices]\n",
    "            y_batch = y[indices]\n",
    "        \n",
    "            output = self.forward(X_batch)\n",
    "            loss = self.compute_loss(y_batch, output)\n",
    "            self.backward(X_batch, y_batch, output)\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Loss at epoch {epoch}: {loss}')\n",
    "                \n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return output\n",
    "    \n",
    "\n",
    "# --- Cross-Validation Training ---\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "input_size = 16\n",
    "output_size = 2\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 128\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "fold = 1\n",
    "\n",
    "# Lists to collect metrics for each fold\n",
    "acc_scores = []\n",
    "prec_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Reset indices for X_train to ensure proper integer indexing\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "# y_train is already a NumPy array\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    # Use .iloc for DataFrame indexing and numpy indexing for y_train\n",
    "    X_tr, X_val = x_train_resample.iloc[train_index], x_train_resample.iloc[val_index]\n",
    "    y_tr, y_val = y_train_resample[train_index], y_train_resample[val_index]\n",
    "    \n",
    "    nn = NN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "    print(f\"Training on fold {fold}: {X_tr.shape[0]} samples\")\n",
    "    \n",
    "    nn.train(X_tr, y_tr, epochs=5000, batch_size=2000)\n",
    "    \n",
    "    # Evaluate on the validation set from the current fold\n",
    "    y_val_trye = np.argmax(y_val, axis=1)\n",
    "    # obtain the predicted class probabilities\n",
    "    y_val_pred = nn.predict(X_val)\n",
    "    y_val_pred = np.argmax(y_val_pred, axis=1)\n",
    "    \n",
    "    # Compute and print accuracy and classification report for the current fold\n",
    "    binary_acc = accuracy_score(y_val_trye, y_val_pred)\n",
    "    acc_scores.append(binary_acc)\n",
    "    print(f\"Accuracy on fold {fold}: {binary_acc}\")\n",
    "    print(classification_report(y_val_trye, y_val_pred))\n",
    "    \n",
    "    fold += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_true = np.argmax(y_test, axis=1)\n",
    "y_test_pred = nn.predict(X_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "print(classification_report(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
